{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomasz/.local/share/virtualenvs/housing-H0uHnK4R/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/tomasz/.local/share/virtualenvs/housing-H0uHnK4R/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5b63430f04e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_predictors = pd.get_dummies(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_train, df_test], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering2(data):\n",
    "    non_numeric = data.select_dtypes(include=object).columns.tolist()\n",
    "    no_missing = list()\n",
    "    for col in non_numeric:\n",
    "        if data[col].notna().all():\n",
    "            no_missing.append(col)\n",
    "    categorize_cols(data, no_missing)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_cols(data, columns):\n",
    "    for col in columns:\n",
    "        data[col+\"_cat\"] = pd.factorize(data[col])[0]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_engineering2(sub_train)\n",
    "choosen_cols = choose_cols(sub_train)\n",
    "print(choosen_cols)\n",
    "heal_cols(sub_train, choosen_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sub_train[choosen_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sub_train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(model, trX, valX, trY, valY):\n",
    "    model.fit(trX,trY)\n",
    "    #print(max(model.feature_importances_))\n",
    "    predictionTest = model.predict(valX)\n",
    "    predictionTrain = model.predict(trX)\n",
    "    return mean_absolute_error(valY, predictionTest), mean_absolute_error(trY,predictionTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = list()\n",
    "test_result = list()\n",
    "leafs = list()\n",
    "min_test = 10000000\n",
    "best_leaf = 5007\n",
    "for max_leaf in range(50,5000,1000):\n",
    "    model = RandomForestRegressor(n_estimators=110, max_leaf_nodes= max_leaf, n_jobs=-1)\n",
    "    test , train = mae(model,X_train, X_test, y_train, y_test)\n",
    "    train_result.append(train)\n",
    "    test_result.append(test)\n",
    "    min_test = min(min_test, test)\n",
    "    if min_test == test:\n",
    "        best_leaf = max_leaf\n",
    "    leafs.append(max_leaf)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.plot(leafs, train_result, 'bo-', label='Train')\n",
    "plt.plot(leafs, test_result, 'go-', label='Test')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "print(min_test)\n",
    "print('best max_leaf is %d'%(best_leaf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data):\n",
    "    data['Neighborhood_cat'] = pd.factorize(data.Neighborhood)[0]\n",
    "    data['LotShape_cat'] = pd.factorize(data.LotShape)[0]\n",
    "    data['BldgType_cat'] = pd.factorize(data.BldgType)[0]\n",
    "    data['HouseStyle_cat'] = pd.factorize(data.HouseStyle)[0]\n",
    "    data['MSZoning_cat'] = pd.factorize(data.MSZoning)[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heal_cols(data,cols):\n",
    "    for col in cols:\n",
    "        data[col].fillna(value=int(data[col].mean()), inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_cols(data):\n",
    "    black_list = ['Id', 'SalePrice']\n",
    "    choosen_cols = data.select_dtypes(include=np.number).columns.tolist()\n",
    "    for col in choosen_cols:\n",
    "        if col in black_list:\n",
    "            choosen_cols.remove(col)\n",
    "    return choosen_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_cols = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction( model, data_all, important_cols):\n",
    "    feature_engineering2(data_all)\n",
    "    choosen_cols = important_cols\n",
    "    choosen_cols = choose_cols(data_all)\n",
    "    heal_cols(data_all, choosen_cols)\n",
    "    print(choosen_cols)\n",
    "  #  heal_cols(test_data, choosen_cols)\n",
    "   # heal_cols(train_data, choosen_cols)\n",
    "    test_data = data_all[data_all.SalePrice.isnull()]\n",
    "    train_data = data_all[data_all.SalePrice.notna()]\n",
    "    test_X = test_data[choosen_cols]\n",
    "    train_X = train_data[choosen_cols]\n",
    "    train_y = train_data['SalePrice']\n",
    "    model.fit(train_X, train_y)\n",
    "    print(model.feature_importances_)\n",
    "    feature_importances = pd.DataFrame(model.feature_importances_, index = choosen_cols, columns=['importance']).sort_values('importance', ascending=False)\n",
    "    important_cols = feature_importances.index.tolist()[:11]\n",
    "    print(important_cols)\n",
    "    print(feature_importances)\n",
    "#   for i in range(0,len(model.feature_importances_)):\n",
    "  #      print('feature name %s \\t\\t feature importance %d'%(choosen_cols[i], np.round(model.feature_importances_[i],3)))\n",
    "    prediction = model.predict(test_X)\n",
    "    solution = pd.DataFrame({'Id':test_data.Id, 'SalePrice':prediction})\n",
    "    solution.to_csv('output/solution_more_cols_cat_nest_cols_reduced.csv', index=False)\n",
    "    return important_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'col1':['2','2','5','adf'],'col2':[2,4,5,6]})\n",
    "df2 = pd.DataFrame({'col2':[5,3,6,2,1,563,2]})\n",
    "df3 = pd.concat([df1, df2], sort=False)\n",
    "df3\n",
    "cond = df3.col1.notna()\n",
    "get_df1 = df3[cond]\n",
    "get_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators = 110, max_leaf_nodes=1050, n_jobs=-1, random_state = 0)\n",
    "important_cols = make_prediction(model, df_all, important_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = avg_price_data.groupby('YearBuilt').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data.sort_values('YearBuilt', inplace=True)\n",
    "grouped_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data.plot();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "housing-H0uHnK4R",
   "language": "python",
   "name": "housing-h0uhnk4r"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
